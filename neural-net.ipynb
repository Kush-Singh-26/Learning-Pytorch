{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Procedure\n",
    "- Define the neural network that has some learnable parameters (or weights)\n",
    "- Iterate over a dataset of inputs\n",
    "- Process input through the network\n",
    "- Compute the loss (how far is the output from being correct)\n",
    "- Propagate gradients back into the network’s parameters\n",
    "- Update the weights of the network, typically using a simple update rule: `weight = weight - learning_rate * gradient`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Process\n",
    "- Each filter has 𝑛 slices, where each slice corresponds to an input channel.\n",
    "- Perform element-wise multiplication between each filter slice and its corresponding input channel.\n",
    "- Sum the results across all slices of the filter.\n",
    "- The final sum is stored as one value in the output feature map.\n",
    "- Repeat this process for every spatial position in the input.\n",
    "- Each filter produces one output channel, so with m filters, we get m output channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input shape = (3,5,5) → 3 channels (RGB), 5×5 size\n",
    "- Filter shape = (3,3,3) → 3 slices per filter, 3×3 kernel size.\n",
    "- Number of filters = 4 → So, output has 4 channels.\n",
    "- Output shape = (4,3,3) (assuming no padding and stride 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convolution process involves:\n",
    "\n",
    "1. Sliding the filter (kernel) over the input:\n",
    "    - The filter moves across the input image in small steps (defined by stride).\n",
    "\n",
    "2. Performing element-wise multiplication:\n",
    "    - At each position, the corresponding values of the input and the filter are multiplied element-wise.\n",
    "\n",
    "3. Summing the results:\n",
    "    - The sum of all element-wise products gives one value in the output feature map.\n",
    "\n",
    "4. Repeating this process for every position in the input:\n",
    "    - This creates the full output feature map.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset\n",
    "- image size = `(28, 28, 1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![nn image](images/mnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, imput):\n",
    "        \n",
    "        c1 = F.relu(self.conv1(input))\n",
    "\n",
    "        s2 = F.max_pool2d(c1, (2,2))\n",
    "\n",
    "        c3 = F.relu(self.conv2(s2))\n",
    "\n",
    "        s4 = F.max_pool2d(c3, 2)\n",
    "\n",
    "        s4 = torch.flatten(s4, 1)\n",
    "\n",
    "        f5 = F.relu(self.fc1(s4))\n",
    "\n",
    "        f6 = F.relu(self.fc2(f5))\n",
    "\n",
    "        output = self.fc3(f6)\n",
    "\n",
    "        return output\n",
    "\n",
    "net = Net()\n",
    "print(net)  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of each layer\n",
    "- **c1** \n",
    "    - 1 input image channel\n",
    "    - 6 output channel\n",
    "    - 5x5 square convolution => kernel size = 5\n",
    "    - ReLU activation\n",
    "    - output = Tesor of size (N, 6, 28, 28) , [N = batch size]\n",
    "\n",
    "- **s2**\n",
    "    - maxpooling using 2x2 grid\n",
    "    - output size = (N, 6, 14, 14)\n",
    "\n",
    "- **c3**\n",
    "    - 6 input channel\n",
    "    - 16 uptput channel\n",
    "    - 5x5 square convolution => kernel size = 5\n",
    "    - ReLU activation\n",
    "    - output = Tesor of size (N, 16, 10, 10) \n",
    "\n",
    "- **s4**\n",
    "    - maxpooling using 2x2 grid\n",
    "    - output size = (N, 16, 5, 5)\n",
    "    - (n, 400) tensor input\n",
    "    - output = (n, 120) tensor\n",
    "    - ReLU activation\n",
    "\n",
    "- **f5**\n",
    "    - (n, 120) tensor input\n",
    "    - output = (n, 84) tensor\n",
    "    - ReLU activation\n",
    "\n",
    "- **f6**\n",
    "    - (n, 84) tensor input\n",
    "    - output = (n, 10) tensor\n",
    "    - ReLU activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1089, -0.0595, -0.0289, -0.0165, -0.0364,  0.0878,  0.0088,  0.0986,\n",
      "         -0.0687, -0.0658]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# random input\n",
    "\n",
    "input = torch.rand(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when call loss.backward(), the whole graph is differentiated w.r.t. the neural net parameters, and all Tensors in the graph that have requires_grad=True will have their .grad Tensor accumulated with the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2746, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)\n",
    "target = target.view(1, -1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "      -> flatten -> linear -> relu -> linear -> relu -> linear\n",
    "      -> MSELoss\n",
    "      -> loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward0 object at 0x00000216D487DCC0>\n",
      "<AddmmBackward0 object at 0x00000216D49374C0>\n",
      "<AccumulateGrad object at 0x00000216D49374C0>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)\n",
    "print(loss.grad_fn.next_functions[0][0])\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "None\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0001,  0.0101, -0.0135,  0.0102, -0.0006,  0.0000])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight = weight - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
